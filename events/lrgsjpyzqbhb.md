## Feature Selection
### 5 December 2019
RSVPs: 34 | Waiting: 0 | Event Type: physical | [Meetup Event Link](https://www.meetup.com/Data-Science-Discussion-Auckland/events/266288264)

We have looked at feature engineering, clustering and dimensionality reduction. And now, after creating hundreds of features from our data to try to help our model, we are left with the question of "which features should we keep?". We know that by discarding some of the features we can improve our model, but which features do we discard and which do we keep?

Feature selection will be the topic for this meetup. Here is some material on the topic:
- Introductory blog: [https://machinelearningmastery.com/an-introduction-to-feature-selection/](https://machinelearningmastery.com/an-introduction-to-feature-selection/)
- Feature Selection with Ensembles, Artificial Variables, and Redundancy Elimination - [http://www.jmlr.org/papers/volume10/tuv09a/tuv09a.pdf](http://www.jmlr.org/papers/volume10/tuv09a/tuv09a.pdf)
- Gradient Boosted Feature Selection: [https://arxiv.org/abs/1901.04055](https://arxiv.org/abs/1901.04055)

Please attempt to read some of the material before the Meetup. It is fine if you do not understand it all. The purpose of this meetup to ask any questions about where you are unsure so that we can all learn.

Have a think about any research papers or Kaggle competitions you would like to discuss in future meetups. We will spend a few minutes on this at the end

Meeting Schedule:

6:00 - 6:30 - Arrive at venue
6:30 - Introductions
6:35 - Discussion
7:25 - Discuss and decide on next topic
7:30 - Meeting ends

A big 'Thank you' to GridAKL for providing the venue!
