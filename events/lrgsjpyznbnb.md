## Class Imbalance with XGBoost
### 10 October 2019
RSVPs: 32 | Waiting: 0 | Event Type: physical | [Meetup Event Link](https://www.meetup.com/Data-Science-Discussion-Auckland/events/264448601)

Does your cat and dog classifier dataset only have 100 pictures of cats and 5000 pictures of dogs? Does the thought of obtaining 4900 more cat photos to make your dataset balanced make you feel nauseous?

If so, this paper may have the answer that you are looking for: Imbalance-XGBoost: Leveraging Weighted and Focal Losses for
Binary Label-Imbalanced Classification with XGBoost' [https://arxiv.org/pdf/1908.01672.pdf](https://arxiv.org/pdf/1908.01672.pdf) with github code here: [https://github.com/jhwjhw0123/Imbalance-XGBoost](https://github.com/jhwjhw0123/Imbalance-XGBoost)

This meeting, we will discuss the above paper. Please take a look at the material before coming to the meet up. It is fine if you do not understand it all. The purpose of this meetup to ask any questions about where you are unsure and to learn.

Also at this meetup, feel free to share any progress or ask questions about the Earthquake competition that we have been looking at: [https://www.drivendata.org/competitions/57/nepal-earthquake/](https://www.drivendata.org/competitions/57/nepal-earthquake/) or maybe you want to use this competition to try out what is in this paper?

Have a think about any research papers or Kaggle competitions you would like to discuss in future meetups. We will spend a few minutes on this at the end

Meeting Schedule:

6:00 - 6:30 - Arrive at venue
6:30 - Introductions
6:35 - Discussion
7:25 - Discuss and decide on next topic
7:30 - Meeting ends

A big 'Thank you' to GridAKL for providing the venue!
