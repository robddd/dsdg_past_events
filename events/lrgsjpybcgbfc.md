## The Transformer (NLP)
### 23 April 2020
RSVPs: 41 | Waiting: 0 | Event Type: physical | [Meetup Event Link](https://www.meetup.com/Data-Science-Discussion-Auckland/events/269648857)

Our group survey earlier in the year showed that there are a lot of people interested in NLP topics. This week, we are going to look at the model architecture which has, in the last few years dominated the leaderboards for the highest performance over different NLP tasks.

It is what CNNs are to images, an essential building block which allowed models like BERT and its variations to be so incredibly succesful. It is "The Transformer".

We will focus on this easy to follow illustrated blog post: [http://jalammar.github.io/illustrated-transformer/](http://jalammar.github.io/illustrated-transformer/)

Add if that isnt enough for you, we suggest these two more:
- [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762) (Original paper proposing the transformer)
- [https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) (A blog post from the same author about the 'attention' mechanism)

As always we encourage you to read the material before coming to the meet up. It is fine if you do not understand it all. The purpose of this meetup to learn and to ask questions.

Have a think about any research papers or Kaggle competitions you would like to discuss in future meetups. We will spend a few minutes on this at the end.

Information about connecting to the meeting will be sent out closer to the time.
